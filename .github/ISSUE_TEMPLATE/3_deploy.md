---
name: 3. 模型部署
about: 模型部署相关问题，包括高性能推理、服务化部署、端侧部署等
title: ''
labels: ''
assignees: ''

---

## Checklist:

- [ ] 查找[历史相关issue](https://github.com/PaddlePaddle/PaddleX/issues)寻求解答
- [ ] 翻阅[FAQ](https://paddlepaddle.github.io/PaddleX/main/FAQ.html)
- [ ] 翻阅[PaddleX 文档](https://paddlepaddle.github.io/PaddleX/main/index.html)
- [ ] 确认bug是否在新版本里还未修复

## 描述问题

## 复现

1. 高性能推理

    * 您是否完全按照[高性能推理文档教程](https://paddlepaddle.github.io/PaddleX/main/pipeline_deploy/high_performance_inference.html)跑通了流程？

2. 服务化部署

    * 您是否完全按照[服务化部署文档教程](https://paddlepaddle.github.io/PaddleX/main/pipeline_deploy/serving.html)跑通了流程？

    * 您在服务化部署中是否有使用高性能推理插件？

    * 您使用了哪一种服务化部署方案？

    * 如果是多语言调用的问题，请给出调用示例子。

3. 端侧部署
    * 您是否完全按照[端侧部署文档教程](https://paddlepaddle.github.io/PaddleX/main/pipeline_deploy/edge_deploy.html)跑通了流程？

    * 您使用的端侧设备是？对应的PaddlePaddle版本和PaddleLite版本分别是什么？


3. 您使用的**模型**和**数据集**是？

4. 请提供您出现的报错信息及相关log

## 环境

1. 请提供您使用的PaddlePaddle、PaddleX版本号、Python版本号

3. 请提供您使用的操作系统信息，如Linux/Windows/MacOS

4. 请问您使用的CUDA/cuDNN的版本号是？
